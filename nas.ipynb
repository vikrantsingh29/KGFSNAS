{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torch\n",
    "!pip install numpy\n",
    "!pip install nni"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cxjwxjZ0Sh9g",
    "outputId": "80519f5a-2a9b-4c9d-b1c1-9580dce12a68",
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.707215300Z",
     "start_time": "2023-11-08T05:05:09.246639700Z"
    }
   },
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (2.1.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: filelock in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from torch) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from torch) (2023.9.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (1.26.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nni in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (3.0)\n",
      "Requirement already satisfied: astor in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (0.8.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (0.4.6)\n",
      "Requirement already satisfied: filelock<3.12 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (3.11.0)\n",
      "Requirement already satisfied: json-tricks>=3.15.5 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (3.17.3)\n",
      "Requirement already satisfied: nvidia-ml-py in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (12.535.133)\n",
      "Requirement already satisfied: packaging in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (23.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (2.1.2)\n",
      "Requirement already satisfied: prettytable in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (3.9.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (5.9.6)\n",
      "Requirement already satisfied: PythonWebHDFS in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (0.2.3)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (2.31.0)\n",
      "Requirement already satisfied: responses in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (0.24.0)\n",
      "Requirement already satisfied: schema in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (0.7.5)\n",
      "Requirement already satisfied: scikit-learn>=0.24.1 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (1.3.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (4.66.1)\n",
      "Requirement already satisfied: typeguard<4.1.3,>=3.0.0 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (4.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7.0 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (4.8.0)\n",
      "Requirement already satisfied: websockets>=10.1 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (1.26.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from nni) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from scikit-learn>=0.24.1->nni) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from scikit-learn>=0.24.1->nni) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from typeguard<4.1.3,>=3.0.0->nni) (6.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from pandas->nni) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from pandas->nni) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from pandas->nni) (2023.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from prettytable->nni) (0.2.9)\n",
      "Requirement already satisfied: simplejson in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from PythonWebHDFS->nni) (3.19.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from requests->nni) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from requests->nni) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from requests->nni) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from requests->nni) (2023.7.22)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from schema->nni) (21.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from importlib-metadata>=3.6->typeguard<4.1.3,>=3.0.0->nni) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vikrant.singh\\pycharmprojects\\kgfsnas\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->nni) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import nni"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.859207300Z",
     "start_time": "2023-11-08T05:05:23.715205100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.893207700Z",
     "start_time": "2023-11-08T05:05:23.730210500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "def read_triples_from_file(filename):\n",
    "    \"\"\"\n",
    "    Reads triples from a file.\n",
    "    Assumes each line of the file is in the format: head relation tail.\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            h, r, t = line.strip().split()\n",
    "            triples.append((h, r, t))\n",
    "    return triples\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.894211900Z",
     "start_time": "2023-11-08T05:05:23.749231400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\vikrant.singh\\\\PycharmProjects\\\\KGFSNAS\\\\Countries-S1\\\\'\n",
    "train_triples_string = read_triples_from_file(path + 'train.txt')\n",
    "test_triples_string = read_triples_from_file(path + 'test.txt')\n",
    "valid_triples_string = read_triples_from_file(path + 'valid.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.908204500Z",
     "start_time": "2023-11-08T05:05:23.772204500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# Combine all triples to extract unique entities and relations\n",
    "all_triples = train_triples_string + test_triples_string + valid_triples_string\n",
    "\n",
    "# Get unique entities and relations\n",
    "all_entities = list(set([h for h, _, _ in all_triples] + [t for _, _, t in all_triples]))\n",
    "all_relations = list(set([r for _, r, _ in all_triples]))\n",
    "\n",
    "\n",
    "# Map entities and relations to indices\n",
    "entity_to_index = {entity: idx for idx, entity in enumerate(all_entities)}\n",
    "relation_to_index = {relation: idx for idx, relation in enumerate(all_relations)}\n",
    "\n",
    "# Convert the string triples to their respective indices\n",
    "train_triples = [(entity_to_index[h], relation_to_index[r], entity_to_index[t]) for h, r, t in train_triples_string]\n",
    "test_triples = [(entity_to_index[h], relation_to_index[r], entity_to_index[t]) for h, r, t in test_triples_string]\n",
    "valid_triples = [(entity_to_index[h], relation_to_index[r], entity_to_index[t]) for h, r, t in valid_triples_string]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.909211500Z",
     "start_time": "2023-11-08T05:05:23.796203300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 2\n",
      "Number of total triples:  1159\n",
      "Number of training triples:  1111\n",
      "Number of validation triples:  24\n",
      "Number of test triples:  24\n"
     ]
    }
   ],
   "source": [
    "# Determine the number of unique entities and relations based on the loaded data\n",
    "num_entities = len(all_entities)\n",
    "num_relations = len(all_relations)\n",
    "print(num_entities , num_relations)\n",
    "print(\"Number of total triples: \", len(all_triples))\n",
    "print(\"Number of training triples: \", len(train_triples))\n",
    "print(\"Number of validation triples: \", len(valid_triples))\n",
    "print(\"Number of test triples: \", len(test_triples))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.911201700Z",
     "start_time": "2023-11-08T05:05:23.825225300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "x_samples = torch.linspace(-1, 1, 50).to(device)\n",
    "\n",
    "# Create embedding layers\n",
    "\n",
    "entity_embeddings = nn.Embedding(num_entities, embedding_dim).to(device)\n",
    "relation_embeddings = nn.Embedding(num_relations, embedding_dim).to(device)\n",
    "\n",
    "all_entity_indices = list(range(num_entities))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.944204700Z",
     "start_time": "2023-11-08T05:05:23.844211500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "\n",
    "def generate_negative_triples(true_triple, all_entity_indices, num_samples, true_triples_list):\n",
    "    h, r, t = true_triple\n",
    "    negative_triples = set()\n",
    "\n",
    "    while len(negative_triples) < num_samples:  # Generate num_samples number of negative triples\n",
    "        t_corrupted = random.choice(all_entity_indices)  # Corrupt tail\n",
    "\n",
    "        if (h, r,\n",
    "            t_corrupted) not in true_triples_list and t_corrupted != t:\n",
    "            negative_triples.add((h, r, t_corrupted))\n",
    "\n",
    "    return list(negative_triples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:23.945202Z",
     "start_time": "2023-11-08T05:05:23.869213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def complex_num(embedding):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes a complex number representation given an embedding and a set of x_samples.\n",
    "    Returns a complex number representation in the form of c = cos(x) + i*sin(x).\n",
    "    \"\"\"\n",
    "    # Compute the real and imaginary parts\n",
    "    real_part = (embedding * torch.cos(x_samples.unsqueeze(-1))).sum(-1)\n",
    "    imag_part = (embedding * torch.sin(x_samples.unsqueeze(-1))).sum(-1)\n",
    "\n",
    "    # Combine real and imaginary parts\n",
    "    # complex_representation = torch.stack((real_part, imag_part), dim=-1)  # Shape: [x_samples, 2]\n",
    "    # Aggregate real and imaginary parts\n",
    "    complex_representation = real_part + imag_part # Shape: [x_samples]\n",
    "\n",
    "    return complex_representation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.038211800Z",
     "start_time": "2023-11-08T05:05:23.885211900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def polynomial(embedding):\n",
    "\n",
    "    \"\"\"\n",
    "    Computes a polynomial given an embedding and a set of x_samples.\n",
    "    Returns a polynomial vector representation.\n",
    "    \"\"\"\n",
    "    # The polynomial is in the form of a_0 + a_1*x + a_2*x^2 + ...\n",
    "\n",
    "    embedding = embedding\n",
    "\n",
    "    # Extend dimensions for broadcasting\n",
    "    emb_expanded = embedding.unsqueeze(0)  # Shape: [1, embedding_dim]\n",
    "    x_expanded = x_samples.unsqueeze(1)  # Shape: [num_samples, 1]\n",
    "\n",
    "    # Calculate polynomial values using broadcasting\n",
    "    powers_of_x = x_expanded ** torch.arange(len(embedding)).to(embedding.device)\n",
    "  # Shape: [num_samples, embedding_dim]\n",
    "    poly_vector = (emb_expanded * powers_of_x).sum(dim=-1)  # Element-wise multiplication followed by sum\n",
    "\n",
    "    return poly_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.110200800Z",
     "start_time": "2023-11-08T05:05:23.901215100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Mish(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "\n",
    "    super().__init__()\n",
    "\n",
    "    # Input dim should match input data\n",
    "    l1_dim = input_dim\n",
    "\n",
    "    # Calculate hidden layer dims\n",
    "    # l2_dim = l1_dim // 2\n",
    "    # l3_dim = l2_dim // 2\n",
    "    l2_dim = l1_dim\n",
    "    l3_dim = l2_dim\n",
    "\n",
    "    # Output dim\n",
    "    l4_dim = output_dim\n",
    "\n",
    "    # Layer definitions\n",
    "    self.fc1 = nn.Linear(l1_dim, l2_dim)\n",
    "    self.fc2 = nn.Linear(l2_dim, l3_dim)\n",
    "    self.fc3 = nn.Linear(l3_dim, l4_dim)\n",
    "    self.fc4 = nn.Linear(l4_dim, output_dim)\n",
    "\n",
    "  def forward(self, input_embedding):\n",
    "    x = x_samples\n",
    "    combined_input = torch.cat((input_embedding.unsqueeze(0), x.unsqueeze(0)), dim=1)  # Shape: [1, 100]\n",
    "    out = Mish()(self.fc1(combined_input))\n",
    "    out = Mish()(self.fc2(out))\n",
    "    out = Mish()(self.fc3(out))\n",
    "    out = self.fc4(out)\n",
    "    return out.squeeze(0)  # Shape: [50]\n",
    "\n",
    "  # def forward(self, input_embedding, x_samples):\n",
    "  # \n",
    "  # \n",
    "  #   # Layer 1\n",
    "  #   out1 = torch.tanh(self.fc1(x))\n",
    "  # \n",
    "  #   # Layer 2\n",
    "  #   out2 = torch.tanh(self.fc2(out1))\n",
    "  # \n",
    "  #   # Layer 3\n",
    "  #   out3 = torch.tanh(self.fc3(out2))\n",
    "  # \n",
    "  #   # Layer 4\n",
    "  #   out4 = self.fc4(out3)\n",
    "  # \n",
    "  #   return out4\n",
    "\n",
    "neural_network = NeuralNet(100, 50)\n",
    "neural_network = neural_network.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.145203200Z",
     "start_time": "2023-11-08T05:05:23.923202800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_layers, layer_size, dropout_rate, activation_function):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.activation_function = activation_function\n",
    "        \n",
    "        for i in range(num_layers):\n",
    "            in_dim = 50 if i == 0 else layer_size  # Assuming input_dim is 100\n",
    "            out_dim = in_dim if i == num_layers - 1 else layer_size  # Assuming output_dim is 50\n",
    "            self.layers.append(nn.Linear(in_dim, out_dim))\n",
    "\n",
    "    def forward(self, input_embedding, x):\n",
    "        x = torch.cat((input_embedding.unsqueeze(0), x.unsqueeze(0)), dim=1)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            if self.activation_function == 'relu':\n",
    "                x = torch.relu(x)\n",
    "            elif self.activation_function == 'tanh':\n",
    "                x = torch.tanh(x)\n",
    "            elif self.activation_function == 'sigmoid':\n",
    "                x = torch.sigmoid(x)\n",
    "            x = self.dropout(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.147209500Z",
     "start_time": "2023-11-08T05:05:23.956203900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "\n",
    "def compute_score(h_idx, r_idx, t_idx):\n",
    "\n",
    "\n",
    "    h = entity_embeddings(torch.tensor([h_idx]).to(device))[0]\n",
    "    r = relation_embeddings(torch.tensor([r_idx]).to(device))[0]\n",
    "    t = entity_embeddings(torch.tensor([t_idx]).to(device))[0]\n",
    "\n",
    "    fh = FUNCTION_MAP[FUNCTION_SPACE](h)\n",
    "    ft = FUNCTION_MAP[FUNCTION_SPACE](t)\n",
    "    fhx = FUNCTION_MAP[FUNCTION_SPACE](fh)\n",
    "    h_r_combined = h * r  # element-wise multiplication of h and r\n",
    "    frh = FUNCTION_MAP[FUNCTION_SPACE](h_r_combined)\n",
    "\n",
    "    score = torch.trapz(frh * ft, x_samples, dim=0)\n",
    "\n",
    "    return score\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.148219200Z",
     "start_time": "2023-11-08T05:05:23.976200500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "data": {
      "text/plain": "'Vector Triple Product (VTP) Scoring Function:\\n\\nscore=∫fh⋅(fr⊙ft)dx\\n'"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compute_vtp_score(h_idx, r_idx, t_idx):\n",
    "\n",
    "    # Fetching the embeddings for the head, relation, and tail entities on GPU\n",
    "    h = entity_embeddings(torch.tensor([h_idx]).to(device))[0]\n",
    "    r = relation_embeddings(torch.tensor([r_idx]).to(device))[0]\n",
    "    t = entity_embeddings(torch.tensor([t_idx]).to(device))[0]\n",
    "\n",
    "    # Transform the embeddings using the polynomial function\n",
    "    fh = FUNCTION_MAP[FUNCTION_SPACE](h)\n",
    "    fr = FUNCTION_MAP[FUNCTION_SPACE](r)\n",
    "    ft = FUNCTION_MAP[FUNCTION_SPACE](t)\n",
    "\n",
    "    # Compute the VTP score using the transformed embeddings\n",
    "\n",
    "    # score = torch.sum(fh * (fr * ft))\n",
    "    score = - torch.trapz(ft, x_samples, dim=0) * torch.trapz(fh * fr, x_samples, dim=0) + torch.trapz(fr, x_samples, dim=0) * torch.trapz(ft * fh, x_samples, dim=0)\n",
    "    return score\n",
    "\n",
    "\"\"\"Vector Triple Product (VTP) Scoring Function:\n",
    "\n",
    "score=∫fh⋅(fr⊙ft)dx\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.151209100Z",
     "start_time": "2023-11-08T05:05:23.991201200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "'Trilinear Scoring Function:\\n\\nscore=∫fh⋅fr⋅ftdx\\n'"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compute_trilinear_score(h_idx, r_idx, t_idx):\n",
    "\n",
    "    h = entity_embeddings(torch.tensor([h_idx]).to(device))[0]\n",
    "    r = relation_embeddings(torch.tensor([r_idx]).to(device))[0]\n",
    "    t = entity_embeddings(torch.tensor([t_idx]).to(device))[0]\n",
    "\n",
    "    fh = FUNCTION_MAP[FUNCTION_SPACE](h)\n",
    "    fr = FUNCTION_MAP[FUNCTION_SPACE](r)\n",
    "    ft = FUNCTION_MAP[FUNCTION_SPACE](t)\n",
    "\n",
    "    # score = torch.sum(fh * fr * ft)  # Element-wise multiplication across the three vectors\n",
    "    score = torch.trapz(fh * fr * ft, x_samples, dim=0)\n",
    "\n",
    "    return score\n",
    "\n",
    "\"\"\"Trilinear Scoring Function:\n",
    "\n",
    "score=∫fh⋅fr⋅ftdx\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.156207200Z",
     "start_time": "2023-11-08T05:05:24.008204200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "\n",
    "# Print weights before training\n",
    "# print(\"Weights before training:\")\n",
    "# for name, param in neural_network.named_parameters():\n",
    "#     print(name, param.data)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam([\n",
    "    {'params': entity_embeddings.parameters()},\n",
    "    {'params': relation_embeddings.parameters()},\n",
    "     {'params': neural_network.parameters() }\n",
    "], lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.157204Z",
     "start_time": "2023-11-08T05:05:24.026201900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "\n",
    "margin = 1.0\n",
    "criterion = nn.MarginRankingLoss(margin=margin)\n",
    "\n",
    "def compute_loss(positive_score, negative_score):\n",
    "    y = torch.ones_like(positive_score) \n",
    "    loss = criterion(positive_score, negative_score, y)\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.159198200Z",
     "start_time": "2023-11-08T05:05:24.042205Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "def calculate_loss_BCELogistLoss(pos_scores, neg_scores):\n",
    "    # Convert scores to probabilities\n",
    "    pos_probs = torch.sigmoid(pos_scores)\n",
    "    neg_probs = torch.sigmoid(neg_scores)\n",
    "\n",
    "    # True labels\n",
    "    pos_labels = torch.ones_like(pos_scores)\n",
    "    neg_labels = torch.zeros_like(neg_scores)\n",
    "\n",
    "    # BCELoss for positive and negative triples\n",
    "    pos_loss = F.binary_cross_entropy(pos_probs, pos_labels)\n",
    "    neg_loss = F.binary_cross_entropy(neg_probs, neg_labels)\n",
    "\n",
    "    # Combine the losses\n",
    "    total_loss = pos_loss + neg_loss\n",
    "\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.230200300Z",
     "start_time": "2023-11-08T05:05:24.058201300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "def l2_loss(pos_scores, neg_scores):\n",
    "    margin = 1\n",
    "    return torch.sum(F.relu( neg_scores - pos_scores+ margin))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.230200300Z",
     "start_time": "2023-11-08T05:05:24.069205900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [],
   "source": [
    "# Function spaces\n",
    "POLYNOMIAL = 'polynomial'\n",
    "COMPLEX = 'complex'\n",
    "NN = 'neural_network'\n",
    "\n",
    "# Scoring functions\n",
    "VTP = 'vtp'\n",
    "TRILINEAR = 'trilinear'\n",
    "COMPOSITIONAL = 'compute_score'\n",
    "\n",
    "# Loss Functions\n",
    "BCE = \"Binary cross entropy with logist loss\"\n",
    "L2 = \"L2 Loss\"\n",
    "MARGIN_LOSS_FN = \"Margin based loss function\"\n",
    "\n",
    "# Global variables (initial values can be None or some default value)\n",
    "FUNCTION_SPACE = None\n",
    "LOSS_FN = None\n",
    "SCORING_FN = None\n",
    "FUNCTION_MAP = None\n",
    "SCORING_MAP = None\n",
    "LOSS_MAP = None\n",
    "\n",
    "def configuration(function_space , loss_function , scoring_function):\n",
    "    global FUNCTION_SPACE, LOSS_FN, SCORING_FN, FUNCTION_MAP, SCORING_MAP, LOSS_MAP\n",
    "\n",
    "    # Select which to use\n",
    "    FUNCTION_SPACE = function_space\n",
    "    LOSS_FN = loss_function\n",
    "    SCORING_FN = scoring_function\n",
    "\n",
    "    # Mapping function space name to function\n",
    "    FUNCTION_MAP = {\n",
    "        POLYNOMIAL: polynomial,\n",
    "        COMPLEX: complex_num,\n",
    "        NN: neural_network\n",
    "    }\n",
    "\n",
    "    # Mapping scoring fn name to function\n",
    "    SCORING_MAP = {\n",
    "        VTP: compute_vtp_score,\n",
    "        TRILINEAR: compute_trilinear_score,\n",
    "        COMPOSITIONAL: compute_score\n",
    "    }\n",
    "\n",
    "    # Mapping loss fn name to function\n",
    "    LOSS_MAP = {\n",
    "        BCE: calculate_loss_BCELogistLoss,\n",
    "        L2: l2_loss,\n",
    "        MARGIN_LOSS_FN: compute_loss\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.230200300Z",
     "start_time": "2023-11-08T05:05:24.085206700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "def compute_MRR(test_triples):\n",
    "    rr_sum = 0.0\n",
    "\n",
    "    for h_idx, r_idx, t_true_idx in test_triples:\n",
    "        scores = []\n",
    "\n",
    "        # Score all entities as potential tails\n",
    "        for t_idx in all_entity_indices:\n",
    "\n",
    "            score = SCORING_MAP[SCORING_FN](h_idx, r_idx, t_idx)\n",
    "            scores.append((t_idx, score.item()))\n",
    "\n",
    "        # Sort entities based on their scores\n",
    "        ranked_entities = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "        rank = [idx for idx, (entity, _) in enumerate(ranked_entities) if entity == t_true_idx][0] + 1\n",
    "        # Add the reciprocal rank to the sum\n",
    "        rr_sum += 1.0 / rank\n",
    "\n",
    "    # Compute the mean reciprocal rank\n",
    "    mrr = rr_sum / len(test_triples)\n",
    "    return mrr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.231198900Z",
     "start_time": "2023-11-08T05:05:24.100202Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "def forward(triples):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for h_idx, r_idx, t_idx in triples:\n",
    "        h_idx, r_idx, t_idx = torch.tensor(h_idx).to(device), torch.tensor(r_idx).to(device), torch.tensor(t_idx).to(device)\n",
    "        # Compute positive score\n",
    "        positive_score = SCORING_MAP[SCORING_FN](h_idx, r_idx, t_idx)\n",
    "\n",
    "        accumulated_loss = 0.0\n",
    "        num_neg_samples = 5\n",
    "        negative_triples = generate_negative_triples((h_idx, r_idx, t_idx), all_entity_indices, num_neg_samples,\n",
    "                                                     train_triples)\n",
    "\n",
    "        for h_neg_idx, r_neg_idx, t_neg_idx in negative_triples:\n",
    "            h_neg_idx, r_neg_idx, t_neg_idx = torch.tensor(h_neg_idx).to(device), torch.tensor(r_neg_idx).to(device), torch.tensor(t_neg_idx).to(device)\n",
    "            # Compute negative score\n",
    "            negative_score =SCORING_MAP[SCORING_FN](h_neg_idx, r_neg_idx, t_neg_idx)\n",
    "\n",
    "            # Compute loss for the positive and negative score pair\n",
    "            loss = LOSS_MAP[LOSS_FN](positive_score, negative_score)\n",
    "            accumulated_loss += loss\n",
    "\n",
    "        accumulated_loss /= num_neg_samples\n",
    "        accumulated_loss.backward()\n",
    "        # for name, param in neural_network.named_parameters():\n",
    "        #   if param.grad is not None:\n",
    "        #      print(name, param.grad)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        # for param in neural_network.parameters():\n",
    "        #   param.grad.zero_\n",
    "\n",
    "        total_loss += accumulated_loss.item()\n",
    "\n",
    "    return total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.234197900Z",
     "start_time": "2023-11-08T05:05:24.117206100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DKxFYqPOOt_t",
    "outputId": "8ecdd74b-c7bb-47bd-b01d-717c4c3d664d",
    "ExecuteTime": {
     "end_time": "2023-11-08T05:05:24.264201300Z",
     "start_time": "2023-11-08T05:05:24.134212500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Training Loop\n",
    "# num_epochs = 100\n",
    "#\n",
    "# for epoch in range(num_epochs):\n",
    "#     configuration(POLYNOMIAL, BCE, VTP)\n",
    "#     total_loss = forward(train_triples)\n",
    "#     print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss}\")\n",
    "#     # print(\"Weights after epoch {}:\".format(epoch+1))\n",
    "#     # for name, param in neural_network.named_parameters():\n",
    "#     #   print(name, param.data)\n",
    "#\n",
    "# # After training, evaluate MRR on test_triples\n",
    "# mrr_value = compute_MRR(test_triples)\n",
    "# print(f\"Mean Reciprocal Rank (MRR) on Test Data: {mrr_value}\")\n",
    "\n",
    "configurations = [\n",
    "    # (POLYNOMIAL, BCE, VTP),\n",
    "    # (POLYNOMIAL, BCE, TRILINEAR),\n",
    "    # (POLYNOMIAL, BCE, COMPOSITIONAL),\n",
    "    # (POLYNOMIAL, L2, VTP),\n",
    "    # (POLYNOMIAL, L2, TRILINEAR),\n",
    "    # (POLYNOMIAL, L2, COMPOSITIONAL),\n",
    "    # (POLYNOMIAL, MARGIN_LOSS_FN, VTP),\n",
    "    # (POLYNOMIAL, MARGIN_LOSS_FN, TRILINEAR),\n",
    "    # (POLYNOMIAL, MARGIN_LOSS_FN, COMPOSITIONAL),\n",
    "    # (COMPLEX, BCE, VTP),\n",
    "    # (COMPLEX, BCE, TRILINEAR),\n",
    "    # (COMPLEX, BCE, COMPOSITIONAL),\n",
    "    # (COMPLEX, L2, VTP),\n",
    "    # (COMPLEX, L2, TRILINEAR),\n",
    "    # (COMPLEX, L2, COMPOSITIONAL),\n",
    "    # (COMPLEX, MARGIN_LOSS_FN, VTP),\n",
    "    # (COMPLEX, MARGIN_LOSS_FN, TRILINEAR),\n",
    "    # (COMPLEX, MARGIN_LOSS_FN, COMPOSITIONAL),\n",
    "    (NN, BCE, VTP),\n",
    "    (NN, BCE, TRILINEAR),\n",
    "    (NN, BCE, COMPOSITIONAL),\n",
    "    (NN, L2, VTP),\n",
    "    (NN, L2, TRILINEAR),\n",
    "    (NN, L2, COMPOSITIONAL),\n",
    "    (NN, MARGIN_LOSS_FN, VTP),\n",
    "    (NN, MARGIN_LOSS_FN, TRILINEAR),\n",
    "    (NN, MARGIN_LOSS_FN, COMPOSITIONAL)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vikrant.singh\\AppData\\Local\\Temp\\ipykernel_9284\\3318445240.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  h_neg_idx, r_neg_idx, t_neg_idx = torch.tensor(h_neg_idx).to(device), torch.tensor(r_neg_idx).to(device), torch.tensor(t_neg_idx).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Loss: 1368.3705550581217\n",
      "Epoch 2/100, Loss: 1145.96029612422\n",
      "Epoch 3/100, Loss: 1024.9280880531296\n",
      "Epoch 4/100, Loss: 954.7481252328726\n",
      "Epoch 5/100, Loss: 938.8094246447122\n",
      "Epoch 6/100, Loss: 919.0183525546454\n",
      "Epoch 7/100, Loss: 913.230746687972\n",
      "Epoch 8/100, Loss: 927.434935840778\n",
      "Epoch 9/100, Loss: 894.0697418957425\n",
      "Epoch 10/100, Loss: 895.348057772615\n",
      "Epoch 11/100, Loss: 878.4622189928778\n",
      "Epoch 12/100, Loss: 873.3729504119328\n",
      "Epoch 13/100, Loss: 867.7647486301903\n",
      "Epoch 14/100, Loss: 871.8891489217599\n",
      "Epoch 15/100, Loss: 846.0486918705283\n",
      "Epoch 16/100, Loss: 854.2228209297609\n",
      "Epoch 17/100, Loss: 799.9602529024069\n",
      "Epoch 18/100, Loss: 711.8620967549068\n",
      "Epoch 19/100, Loss: 677.2129348617964\n",
      "Epoch 20/100, Loss: 623.2470799038856\n",
      "Epoch 21/100, Loss: 613.6213483972242\n",
      "Epoch 22/100, Loss: 605.3844080600466\n",
      "Epoch 23/100, Loss: 548.9850462768976\n",
      "Epoch 24/100, Loss: 535.3195976520947\n",
      "Epoch 25/100, Loss: 531.3505454878905\n",
      "Epoch 26/100, Loss: 530.6764683484798\n",
      "Epoch 27/100, Loss: 528.6330103266519\n",
      "Epoch 28/100, Loss: 495.964562358713\n",
      "Epoch 29/100, Loss: 496.3701054663252\n",
      "Epoch 30/100, Loss: 456.72788174729794\n",
      "Epoch 31/100, Loss: 466.0370186408363\n",
      "Epoch 32/100, Loss: 496.08485652774834\n",
      "Epoch 33/100, Loss: 486.7595483150508\n",
      "Epoch 34/100, Loss: 420.32158943498507\n",
      "Epoch 35/100, Loss: 432.3698446259368\n",
      "Epoch 36/100, Loss: 451.01552482519764\n",
      "Epoch 37/100, Loss: 446.8711136058555\n",
      "Epoch 38/100, Loss: 425.3892842910718\n",
      "Epoch 39/100, Loss: 405.1656818652991\n",
      "Epoch 40/100, Loss: 419.3085252533201\n",
      "Epoch 41/100, Loss: 430.116719563317\n",
      "Epoch 42/100, Loss: 400.29004568618984\n",
      "Epoch 43/100, Loss: 401.64603527262807\n",
      "Epoch 44/100, Loss: 372.0417187891435\n",
      "Epoch 45/100, Loss: 397.1364369239818\n",
      "Epoch 46/100, Loss: 390.23646946635563\n",
      "Epoch 47/100, Loss: 364.80438078379666\n",
      "Epoch 48/100, Loss: 360.3931816186232\n",
      "Epoch 49/100, Loss: 351.2411876800761\n",
      "Epoch 50/100, Loss: 345.4450878461066\n",
      "Epoch 51/100, Loss: 352.01701807643985\n"
     ]
    }
   ],
   "source": [
    "def initialize_weights(embedding):\n",
    "    nn.init.uniform_(embedding.weight.data, -0.05, 0.05)\n",
    "\n",
    "# Assuming you have embedding layers named `entity_embedding` and `relation_embedding`:\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configurations:\n",
    "    initialize_weights(entity_embeddings)\n",
    "    initialize_weights(relation_embeddings)\n",
    "    configuration(*config)\n",
    "\n",
    "    # Training Loop (your existing code)\n",
    "    for epoch in range(100):\n",
    "        total_loss = forward(train_triples)\n",
    "        print(f\"Epoch {epoch + 1}/{100}, Loss: {total_loss}\")\n",
    "\n",
    "    # Evaluation\n",
    "    mrr_value = compute_MRR(test_triples)\n",
    "    print(f\"Configuration: {config}, Mean Reciprocal Rank (MRR) on Test Data: {mrr_value}\")\n",
    "\n",
    "    # Log the results\n",
    "    results.append((config, mrr_value))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-11-08T05:05:24.147209500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "tuned_params = nni.get_next_parameter()\n",
    "num_layers = tuned_params['num_layers']\n",
    "layer_size = tuned_params['layer_size']\n",
    "dropout_rate = tuned_params['dropout_rate']\n",
    "activation_function = tuned_params['activation_function']\n",
    "learning_rate = tuned_params['learning_rate']\n",
    "\n",
    "# Create the NeuralNet instance with the tuned hyperparameters\n",
    "neural_network = NeuralNet(num_layers, layer_size, dropout_rate, activation_function)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ]
}
